---
title: "Lorelogram: describing correlation structure in binary data"
date: "`r format(Sys.time(), '%d %B %Y')`"
bibliography: vignettes/Lorelogram Vignette.bib
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Lorelogram: describing correlation structure in binary data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
```{r, include = FALSE}
knitr::opts_chunk$set(fig.align = "center", fig.width = 6, fig.height = 4, 
  collapse = TRUE,
  comment = "#>", 
  cache = 1, cache.extra = knitr::rand_seed, autodep = TRUE
)
```



# Table of contents
1. [Introduction](#introduction)
2. [How to apply the lorelogram](#paragraph1)
    1. [Data format](#subparagraph1)
3. [Another paragraph](#paragraph2)




# 1. Introduction <a name="introduction"></a>

The __lorelogram__ package provides functions to explore and graphically describe correlation structures in binary data. The package is available on GitHub and can be downloaded in R (@RCoreTeam2018) via:

```{r load pkg, warning = FALSE, message = FALSE, results = 'hide'}
if (!require("devtools")) install.packages("devtools", repos = "http://cran.us.r-project.org", dependencies = "Imports")
devtools::install_github("FabiolaIannarilli/lorelogram", auth_token = "69451dbc8b643e18d5e25b488e0a485b59a93512") 
library(lorelogram)
```

The lorelogram is a very usufel tool to identify dependency structure in binary data, guide data aggregation, explore the effect of covariates on the correlation in the data. It can also be applied to explore the dependency in a certain dataset at different spatial or temporal scales (e.g., camera trap data analyzed at the hour- or minute-scale). See @Iannarilli for examples of applications. The method has been developed by @Heagerty1998 and is based on pairwise log-odds ratio. For more information on the method and on applications in ecological studies see @Iannarilli.

Here we focused on guiding new users on how to apply the lorelogram to their own dataset. We provide step-by-step examples, and compare the efficiency of our `lorelogram` function with other functions for calculating the lorelogram available in R (@RCoreTeam2018). 

The main function in the __lorelogram__ package is called `lorelogram`. This function allows users to calculate log-odds ratio at each spatial or temporal lag up to a maximum interval between subsequent observations. It also returns a plot of these values, the lorelogram plot, that graphically represents how the correlation changes with the increase of the spatial or temporal interval between observations. 

We use the data associated with the package to provide a first example. This dataset consists of detection/nondetection data of gray fox (_Urocyon cinereoargenteus_) collected using camera traps at 100 locations in Northern Minnesota during fall 2016. We provided details on the structure of this data in the [Data format] section whereas further data on the sampling protocol are available at \url{https://drive.google.com/drive/folders/12cx59tZvPndOWqH7TG6XKGPFd6HyBjMR?usp=sharing}. We just load the data and apply the `lorelogram` function. 

```{r ex1}
data("GrayFox_Hour")
lorelogram(GrayFox_Hour, max_lag = 30)
```

The `lorelogram` function returns a data frame containing the estimated average log-odds ratio values and associate 95% confidence interval at each lag (defined by the parameter \code{max_lag}), and a plot of the estimates. The data frame component of the output can be assigned to an object that can be later used as the argument for the function `lor_plot`. This second function allows users to save the plot as a jpeg file in a directory of their choice and have more control on plot features. For example, using `lor_plot` we can assign a title to the plot, change the default label for the x axis and the linetype, specify the color of the 95% confidence interval, the  distance among breaks in the x axis, and the range of the y axis.

```{r ex2}
LORs <- lorelogram(GrayFox_Hour, plot_LOR = FALSE)
lor_plot(LORs, save_LOR_plot = FALSE, title = "My first lorelogram", x_axis_title = "Lag (Hour)", colour="red", linetype = "dashed", x_break = 24, ylim = c(-2,5))
```

# 2. How to apply the lorelogram

In this section we are going to illustrate how to apply the `lorelogram` function to new datasets, briefly explore the differences between empirical and model-based lorelogram, provide some guidance on when and why might be convinient to bin the data, and show how to determine time to independence using a derivate-based approach.   

## 2.1 Data format <a name="data format"></a>

The `lorelogram` function accepts both wide and long data format. Wide format data should contain a sampling unit identifier in the first column and the binary data in the following columns, one for each sampling replicates. Each row should represent a sampling unit. In the wide format, it is important to organize the data into the columns from first to last sampling occasion (with data for the first replicate contained in the second column, second replicate in third column, and so on) because the order of the columns will be then be used by the function to define the spatial or temporal interval between two outcomes at the same sampling unit.

```{r ex3}
GrayFox_Hour[24:28, 1:31]
```
In this subset of the GrayFox_Hour data each column from the second to the last reports the binary data: the dectection of the species during a certain hour is coded as 1, 0 otherwise. The data showed here have been collected at five sites during the first 30 hours of sampling. Note as the columns are ordered from hour 1 (column 'o1') to hour 30 (column 'o30'). NAs indicate occasions in which the camera trap at a certain site was no yet active (e.g., sites 6A and 6C); at site 6B the camera trap was deployed and actived at the 25th hour since the start of the whole period of study. 

In the long format data, information are organized in three columns, that must be organized in the order described here. The first column contains the sampling unit identifier, the second contains numeric values indicating the time or space of each replicate, the last column contains the binary outcome.

```{r ex4}
data("GrayFox_Hour_long")
GrayFox_Hour_long[2501:2520,]
```

These data are a subset of the same gray fox data organized in the long format and show the detection/nondetection outcomes (column 'y') at twenty different camera sites (column 'id') at the 26th hour of sampling (column 'time'). 

Sites in which there are no detection (i.e. no 1s) for the whole sampling period are automatically removed because they do not contain information on correlation among detections. The `lorelogram` function handles missing values (i.e. NAs) in the data; for each sampling units, these values will be removed before creating the pairwise detection histories at the different intervals.

## 2.2 Interpreting the lorelogram

Lorelogram plots provide a graphical description of how the correlation in the data changes with the increase of the interval between sampling occasions. Their interpretation vary based on the resolution of the data (e.g., hour- versus minute-scale), and the context in which it is applied (e.g., spatial versus temporal dependency). Here we provide some general guidance on how to interpret the lorelogram and illustrate this applying the lorelogram to simulated data. In general, log-odds ratio estimates equal to zero suggest no correlation among outcomes x-unit apart. Positive or negative values indicate instead positive or negative correlation, respectively.

We start simulating data with stationary mean (i.e. mean value is constant across the period of study, that is no other correlation structure are preset in the data) that contains a short-term dependency coded as an autocorrelation component of order first order (i.e. AR1). The lorelogram plot is able to describe the structure of the short-term correlation component, with a steep drop in correlation for short lags independence among outcomes at least x-unit apart.

```{r ex 13}
#insert code
```

In the second example, we again simulate a short-term correlation component, but we apply a not-stationary mean. The lorelogram is still able to describe the short-term correlation in the data, but this time the curve levels off at a log-odds ratio values higher than zero. This suggests the presence in the data of correlation structures other than the one targeted by the lorelogram. For other examples see @Iannarilli (fig. 2 and S1-2 in Appendix).

```{r ex 14}
#insert code
```

Methods to account for this residual correlation exists (see @Iannarilli section 3 for a list), but are computationally demanding and not yet ease to implement in R. 

## 2.3 How the `lorelogram` function works 

The lorelogram requires binary data at each sampling unit (e.g. a camera site) summarized at the scale of interest (e.g. by day, hour, or minute). The `lorelogram` function first remove sampling units with no detection and convert the detection/non-detection data from wide to long format if necessary (Fig. 1, step A). Then, for each sampling unit, it pairs outcomes at different replicates based on all the possible combinations of lags ≤\code(max_lag) unit-lag apart (Fig. 1, step B). The combinations are obtained using the function `combinations` in package __arrangements__ @Lai2018, whereas the pairing is performed using the `nest` and `unnest` functions in __tidyverse__ @Hadley2017. For each discrete interval (i.e. 1 through \code(max_lag)), the function tabulated the number of occurrence of each pairwise detection history ‘11’, ‘10’, ‘01’, or ‘00’ at each sampling units, and then pool data across units if more then one unit has been sampled (Fig. 1, step C). In the empirical lorelogram, these values are used to calculate the average log-odds ratio value at each interval as: $LOR=\log{\frac{n_{11}n_{00}}{n_{01}n_{01}}}$ . The 95% confidence interval at each lag is calculated as: $CI^{95\%} = LOR\pm1.96*\sqrt{\frac{1}{n_{11}}+\frac{1}{n_{00}}+\frac{1}{n_{10}}+\frac{1}{n_{11}}}$.
![Figure 1. Conceptual diagram of the formatting process undergoing in the `lorelogram` function. Example of how camera trap data are converted from detection histories to the counts necessary to calculate the lorelogram values (i.e. pairwise log-odds ratios). Detection histories are first converted from wide to long format (A), then the fucntion compile the outcomes $y_{i}$ and $y_{j}$ as pairwise detections based on all the possible pairwise combinations of time _i_ and _j_ within the maximum time lag ($\Delta t$) considered (B). Finally, for each value of $\Delta t$, we counted the number of 00, 01, 10, 00 detection histories, respectively (C), across all values of _i_ and _j_ that were $\Delta t$ units apart.](C:/Users/Fabiola/Documents/PhD Matherial/LORELOGRAM_TEMPORAL DEPENDENCY/Writing/fig Data formatting_cropped.jpg){width=50%}

<<<<<<< HEAD
## 2.4 Identify the minimum interval to approximate independency

A visual inspection of the lorelogram plot is often sufficient to identify the minimum interval between replicates required to reach (or approximate) independence. However, the __lorelogram__ package provides the `lor_lag_to_indep` function based on derivative that can support a more rigorous selection of this lag threshold. To illustrate how the function works we first simulate same data containing a short-term dependency structure, then we pass this data in the `lorelogram` function and save the results in an object dataframe named _LORs_est_. Finally we use `lor_lag_to_indep` to indentify the minimum interval to approximate independency. 

```{r ex10}
# Load libraries
library(tidyverse)
library(boot)

# Simulation data
set.seed(129)
M <- 30                            # Number of sites
J <- 1000                    # Number of occasions
y <- matrix(NA, nrow=M, ncol=J)     # to store obs values
time <- matrix(data=seq(1,J,1), nrow=M, ncol=J, byrow=TRUE)
b0<-rep(0, J) 

# Simulate ar1 errors 
rho<-0.75 # autocorrelation parameter on logit scale
eps<-matrix(NA, nrow=M, ncol=J) # to hold errors
for(i in 1:M){
  eps[i,1:J]<- t(arima.sim(n =J, list(ar = rho), innov=rnorm(J, mean = 0, sd=0.5))) 
}

#' Determine p's 
p <- inv.logit( matrix(b0, nrow=M, ncol=J, byrow=TRUE) +  eps)   # Detection probability

# Simulate detection process
for(j in 1:J){
  y[,j] <- rbinom(M, 1, p[,j])
}

# create and add ID column to the data and prepare the data
y <- as.data.frame(cbind(id=paste("S", seq(1,M,1), sep=""),y))
colnames(y) <- c("id", paste0("R", seq(1, J, 1), sep=""))

#' Applying lorelogram
LOR_Dep_Stat <- lorelogram(y, max_lag = 30)

#' Identify interval to reach independency
lor_lag_to_indep(LOR_Dep_Stat)
```

The `lor_lag_to_indep` function first 
=======
## 2.4 Binning data

Binning data (i.e. aggregating the data in intervals containing more than one value of lag) can hep reduce the gaps in the lorelogram curves. When there are no detection for a specific lag, the denominator in $LOR=\log{\frac{n_{11}n_{00}}{n_{01}n_{01}}}$ becomes zero and the lod-odds ratio value is undefined for that interval. A common strategy to avoid this problem is to apply the alternative formulation $LOR=\log{\frac{(n_{11}+0.5)(n_{00}+0.5)}{(n_{01}+0.5)(n_{01}+0.5)}}$ CITE FLEISS AGRESTI. However, we prefer to not adopt this solution because we believe is important for users to directly visualize the results directly based on the data they have, without correction to not give them the illusion to have a complete dataset.

For a certain set of data, there is usually an optimal binning value that balances the increasing level of bias with the improvement of precision in the estimates. More extend guidance on this topic is provided in CITE. Our main goal here, when binning data, is reducing gaps in the lorelogram when detection are sparse. Using the \code{bin_width} argument in `lorelogram` users can test several binning values and choose the one that they think is more adeguate for their dataset. To illustrate the process we use the gray fox data, this time organized at the minute scale (instead of hour scale) and selecting only sites where XXXX lure was used. Data are available at \url{drum repository link}.

```{r ex 12}
#insert code
```

## 2.5 Accounting for site-to-site variability

A common source of correlation in ecological studies is that due to variability among sites (i.e. sampling units). In section 2.2 we explore the consequences on the lorelogram of having this additional correlation structures in the data. However, interestingly, estimating log-odds ratio values applying a generalized linear mixed model approach that includes sampling units as a random effect helps on controlling for site-to-site variability. We, thus, provide the option to adopt this method setting the argument \code{lor_type} in `lorelogram` equal to "model-based". We illustrate the process using simulated data containing a short term correlation structure (that is targeted by the lorelogram) and a factor determing site-to-site variability. We simulate data with and without stationary mean and apply `lorelogram`. 

```{r ex 15}
#insert code
```

When estimating the empirical lorelogram, the lorelogram curve levels off at a log-odds ratio value higher than zero, even when data are stationary, due to the site-to-site variability. However, when applying the model-based lorelogram (that includes sites as random effect), the residual correlation due to site-to-site variability is removed.
>>>>>>> 4f9b2df1b8e580cabb7a4c2132ad5e9be358e355

# 3. `lorelogram`: computational time

The most demanding step in terms of computational effort is creating the pairwise detection histories at the different lags (step B in Fig. 1). This step can be quite demanding when estimating log-odds ratios in __large datasets__ because of the large amount of potential pairwise combinations of replications (e.g. $y_{t_{1}},y_{t_{2}}$. For example, a camera trapping period of one week corresponds to 10 080 potential detection events at the minute scale (i.e. 7 days x 24 hours x 60 minutes) for each camera deployed. This results in over 50 million possible combinations of $t_{i},t_{j}$. Even limiting combinations to only those ≤60 minutes apart, decreases this number to just around 603 000 combinations for each camera site. However, describing the detection structure up to 1 hour is sufficient to identify short-term dependency in camera trap data and keeps the computational time and RAM required within acceptable limits. The  `lorelogram` function required ~30 minutes on a regular Windows machine (8 GB; Intel® Core™ i7-4500U CPU @ 1.80GHz 2.40GHz) to compile the lorelogram for time lags between 0 and 60 minutes using 62 days of camera trap data collected from 31 camera sites (see figure 5a in @Iannarilli).

## 3.1  Comparison with other functions

Other functions are avaialable to build lorelograms in R. Specifically, at the time of writing this manuscript, we are aware of two other functions:
 
 *  a script by Nick Strayer available at \url{https://github.com/nstrayer/nviz/blob/master/R/lorelogram.R}. 
 
 *  and the function EVariogram included in the __CompRandFld__ package (\url{https://cran.r-project.org/web/packages/CompRandFld/CompRandFld.pdf}). (spatial).
 
Here we show how the function `lorelogram` in the __lorelogram__ package can handle larger datasets and build lorelogram in a shorter amount of time compared to the other two functions listed above. We also list some advantages and disadvantage of using one option compare to the others. We start importing the example dataset provided within the __lorelogram__ package and the package necessary to perform the test. We use the gray fox data in the long format because this is same format required by the other two functions. We also remove all the sampling units with no detection (`lorelogram` does this internally). In this way, we can make time comparison among functions more direct.  
 
```{r ex5}
# load package and data  
library(tictoc) # for timing the code
library(tidyverse)

data("GrayFox_Hour_long")
str(GrayFox_Hour_long)
# remove sampling units with no detections, then records with NAs (lorelogram::lorelogram does this internally)
GrayFox_Hour_long <- as.data.frame(GrayFox_Hour_long %>% dplyr::group_by(id) %>% dplyr::filter(sum(y, na.rm = TRUE) > 0) %>% droplevels()) 
GrayFox_Hour_long[2:3] <- lapply(GrayFox_Hour_long[2:3], as.numeric)
dim(GrayFox_Hour_long)
head(GrayFox_Hour_long)
range(GrayFox_Hour_long$time) # number of replicates
```

We begin the test by timing Nick Strayer's function. We load the function and apply it to our dataset. This function requires three columns to load the data and a title for the resulting plot (from function's script):
* id = patient or cluster ids
* time = time of measurement
* y = binary outcome
* title = title for the plot produced.

```{r ex6, eval=FALSE, include=FALSE}
# load nstrayer's function and data  
library(devtools)
source_url("https://github.com/nstrayer/nviz/blob/master/R/lorelogram.R?raw=TRUE")  

tic()
lorelogram(id = GrayFox_Hour_long$id, time = GrayFox_Hour_long$time, y = GrayFox_Hour_long$y, title = "Strayer's lorelogram")
toc()

#Error: cannot allocate vector of size 733.7 Gb

```

Strayer's function is focused on temporal datasets and, contrary to `lorelogram`, exclusively adopts a parametric approach to build the lorelogram: it uses a logistic model to 'predict past outcomes from future by utilizing time differences' (as reported in the function). This function does not have a parameter to set the maximum spatial or temporal lag to consider and all the pairwise combinations between replicate number 1 and and last replicate are be considered. This results in extremely long computational time when data contain a large number of replicates, such as in the example dataset (i.e. 1489 temporal replicates).    


The __CompRandFld__ package contains functions to perform parametric statistical inference
with spatial and spatio-temporal datasets based on random fields. The `EVariogram` function, in particular, computes variograms and lorelograms based on the composite likelihood. This function does not handles missing values in the detection/nondetection column, so we are going to remove them first.
```{r ex7}
library(CompRandFld) #EVariogram
library(tidyverse)

GrayFox_Hour_long_noNA <- GrayFox_Hour_long %>% filter(!is.na(y))

# empirical
tic()
lor_Evar <- EVariogram(data = GrayFox_Hour_long_noNA$y, coordx = GrayFox_Hour_long_noNA$time, coordy = rep(1, nrow(GrayFox_Hour_long_noNA)), maxdist = 30, type = "lorelogram", numbins = 30) 
toc() 

# parameter-based
#pml <- FitComposite(GrayFox_Hour_long_noNA$y, coordx = GrayFox_Hour_long_noNA$time, coordy = rep(1, nrow(GrayFox_Hour_long_noNA)), maxdist = 30, model = "BinaryGauss", corrmodel = "exponential")
#Covariogram(pml, vario = lor_Evar, show.vario = TRUE)

```

`EVariogram` requires around 3 minutes to run, about 60 times longer that the `lorelogram` function:

```{r ex8, message = FALSE}
# lorelogram::lorelogram function
tic()
lor_lor <- lorelogram::lorelogram(GrayFox_Hour_long, max_lag = 30, data_format = "long", plot_LOR = FALSE)
toc() 

```

Plotting the results of both the functions we can see that the two curves show the same pattern: a slightly decrease in correlation followed by an increase after time lags of 12 hours (\ref{fig:ex9}). The two curves are, however, in different position in respect of the zero line. This is due to the fact that `EVariogram` handles the non-stationary nature of the data, whereas `lorelogram` does not. Nevertheless, `lorelogram` is able to identify the main correlation structure in the data. Thus, `EVariogram` can be preferred when datasets are not extremely large, whereas `lorelogram` presents computational advantages when working with big data. For example, assessing the short-term correlation (i.e. correlation of outcomes few minutes apart) in 6-week of camera trap data organized at the minute scale (i.e. around 65000 replicates for each surveyed site) is too computational demanding to be performed in a regular laptop using `EVariogram`, but can be done using the `lorelogram`, as showed in @Iannarilli (figure 5); it required ~30 minutes on a regular Windows machine (8 GB; Intel® Core™ i7-4500U CPU @ 1.80GHz 2.40GHz) to compile the lorelogram for time lags between 0 and 60 minutes using 62 days of camera trap data collected from 31 camera sites.

```{r ex9, fig.cap="Green: EVariogram; Red: lorelogram::lorelogram"}
ggplot()+
  geom_line(data = NULL, aes(x = lor_Evar$centers, y = lor_Evar$variograms), col = "green")+
  geom_line(data = lor_lor, aes(x = Lag, y = LORs), col = "red")+
  geom_ribbon(data = lor_lor, aes(x = Lag, ymin = L_95_CI, ymax = U_95_CI), col="red", alpha=0.7, fill="red") +
  geom_hline()
  theme_classic() +
  labs(x = "Time Lag (Hour)", y = "Lorelogram")

```





# References
